{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up: Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "\n",
    "# ----------------- #\n",
    "\n",
    "# Pandas extensions\n",
    "from ingester3.extensions import *\n",
    "\n",
    "# Set up chache manager\n",
    "from ingester3.scratch import cache_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are running version 2.1.0 which is consistent with the documentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tr/3fz1ytg56rbb_68kpd6n0p0h0000gr/T/ipykernel_5872/3737196004.py:2: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import get_distribution\n"
     ]
    }
   ],
   "source": [
    "# Check version of ingester3\n",
    "from pkg_resources import get_distribution\n",
    "installed_version = get_distribution('ingester3').version\n",
    "\n",
    "if installed_version >= '1.8.1':\n",
    "    print (f\"You are running version {installed_version} which is consistent with the documentation\")\n",
    "else:\n",
    "    print (f\"\"\"\n",
    "You are running an obsolete version ({installed_version}). Run:\n",
    "pip install ingester3 --upgrade \n",
    "to upgrade\"\"\")\n",
    "    \n",
    "del installed_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download: Climate Data from CRU and ERA5 data sets\n",
    "- Reasoning for variable choice\n",
    "    - Document with more extensive reasoning for why a variable should or should not be included is in bruno-gbl's repository: https://github.com/bruno-gbl/climate-data-country/blob/main/docs/Variables%20Overview.md\n",
    "    - Document includes information on the variables used in Garret's script to ingest climate variables at the pgm level.\n",
    "    - Document includes more detailed information about the specific coding of the different variables.\n",
    "- CRU vs. ERA5 variables:\n",
    "    - In this script, each climate data variable is either from the CRU or ERA5 climate data set. Both are available through the same World bank Climate Data portal (\"Climate Change Knowledge Portal\" - CCKP).\n",
    "    - However, the structure of the API and the time-span of the two data sets differs slightly. Therefore, they are treated sligthly different before being merged into one dataset.\n",
    "- Data Download Platform\n",
    "    - https://climateknowledgeportal.worldbank.org/download-data\n",
    "    - A user needs to be created to access the API's. However, the API's themselves are not user specific. This script can be run without having an account on the platform.\n",
    "- Data Specifications on the WorldBank Climate Data Platform CCKP:\n",
    "    - CRU data set > timeseries > monthly > 1901-2022 > mean > model \"ts4.07\"\n",
    "    - ERA5 data set > timeseries > monthly > 1950-2023 > mean > model \"era5\" > model label \"x0.25\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function: Download CRU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API Structure for CRU data is as follows:\n",
    "# https://cckpapi.worldbank.org/cckp/v1/cru-x0.5_timeseries_{variable_name}_timeseries_monthly_1901-2022_mean_historical_cru_ts4.07_mean/all_countries?_format=json\n",
    "\n",
    "# Example for the variable \"tas\": API to download JSON file. Can be studied using a normal browser.\n",
    "# https://cckpapi.worldbank.org/cckp/v1/cru-x0.5_timeseries_tas_timeseries_monthly_1901-2022_mean_historical_cru_ts4.07_mean/all_countries?_format=json\n",
    "\n",
    "\n",
    "# Function downloading the climate data from the World Bank Climate Knowledge Portal and turning it from a JSON file into a pandas DataFrame\n",
    "def download_cru_data(cru_variable):\n",
    "        \n",
    "        # Define the URL for the JSON file\n",
    "        url_climate_data = f\"https://cckpapi.worldbank.org/cckp/v1/cru-x0.5_timeseries_{cru_variable}_timeseries_monthly_1901-2022_mean_historical_cru_ts4.07_mean/all_countries?_format=json\"\n",
    "        # Fetch the JSON data using a GET request\n",
    "        response_climate_data = requests.get(url_climate_data)\n",
    "    \n",
    "        # Parse the JSON response into a Python dictionary, if the request was successful\n",
    "        if response_climate_data.status_code == 200:\n",
    "            climate_data_json = response_climate_data.json()\n",
    "        else:\n",
    "            print(f\"Failed to fetch data.\")\n",
    "            climate_data_json = None\n",
    "    \n",
    "        # Flatten the nested structure into a list of dictionaries\n",
    "        climate_data_json_only_data = climate_data_json[\"data\"]\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        for country, timeseries in climate_data_json_only_data.items():\n",
    "            for date, value in timeseries.items():\n",
    "                rows.append({\"Country\": country, \"Date\": date, \"Value\": value})\n",
    "    \n",
    "        # Convert the list into a pandas DataFrame\n",
    "        climate_data_df = pd.DataFrame(rows)\n",
    "    \n",
    "        # Return the DataFrame for further use\n",
    "        return climate_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download: CRU variables that should definitely be adopted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tas // Average Mean Surface Air Temperature // Garret (pgm-level climate data ingestion): Only has a relative temperature variables\n",
    "tas_cru_df = download_cru_data(\"tas\")\n",
    "\n",
    "# tasmax // Average Maximum Surface Air Temperature // Garret (pgm-level climate data ingestion): Only has a relative temperature variables\n",
    "tasmax_cru_df = download_cru_data(\"tasmax\")\n",
    "\n",
    "# tasmin // Average Minimum Surface Air Temperature // Garret (pgm-level climate data ingestion): Only has relative temperature variables\n",
    "tasmin_cru_df = download_cru_data(\"tasmin\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function: Download ERA5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API Structure:\n",
    "# https://cckpapi.worldbank.org/cckp/v1/era5-x0.25_timeseries_{variable_name}_timeseries_monthly_1950-2023_mean_historical_era5_x0.25_mean/all_countries?_format=json\n",
    "\n",
    "# Example for the variable \"cdd65\": API to download JSON file. Can be studied using a normal browser.\n",
    "# https://cckpapi.worldbank.org/cckp/v1/era5-x0.25_timeseries_cdd65_timeseries_monthly_1950-2023_mean_historical_era5_x0.25_mean/all_countries?_format=json\n",
    "\n",
    "\n",
    "# Function downloading the climate data from the World Bank Climate Knowledge Portal and turning it into a pandas DataFrame\n",
    "def download_era5_data(era5_variable):\n",
    "        \n",
    "        # Define the URL for the JSON file\n",
    "        url_climate_data = f\"https://cckpapi.worldbank.org/cckp/v1/era5-x0.25_timeseries_{era5_variable}_timeseries_monthly_1950-2023_mean_historical_era5_x0.25_mean/all_countries?_format=json\"\n",
    "        # Fetch the JSON data using a GET request\n",
    "        response_climate_data = requests.get(url_climate_data)\n",
    "    \n",
    "        # Parse the JSON response into a Python dictionary, if the request was successful\n",
    "        if response_climate_data.status_code == 200:\n",
    "            climate_data_json = response_climate_data.json()\n",
    "        else:\n",
    "            print(f\"Failed to fetch data.\")\n",
    "            climate_data_json = None\n",
    "    \n",
    "        # Flatten the nested structure into a list of dictionaries\n",
    "        climate_data_json_only_data = climate_data_json[\"data\"]\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        for country, timeseries in climate_data_json_only_data.items():\n",
    "            for date, value in timeseries.items():\n",
    "                rows.append({\"Country\": country, \"Date\": date, \"Value\": value})\n",
    "    \n",
    "        # Convert the list into a pandas DataFrame\n",
    "        climate_data_df = pd.DataFrame(rows)\n",
    "    \n",
    "        # Return the DataFrame for further use\n",
    "        return climate_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download: ERA5 variables that should definitely be adopted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdd65 // Cooling Degree Days (ref-65°F)\n",
    "cdd65_era5_df = download_era5_data(\"cdd65\")\n",
    "\n",
    "# hd35 // Number of Hot Days (Tmax > 35°C)\n",
    "hd35_era5_df = download_era5_data(\"hd35\")\n",
    "\n",
    "# hd40 // Number of Hot Days (Tmax > 40°C)\n",
    "hd40_era5_df = download_era5_data(\"hd40\")\n",
    "\n",
    "# hd42 // Number of Hot Days (Tmax > 42°C)\n",
    "hd42_era5_df = download_era5_data(\"hd42\")\n",
    "\n",
    "# hdd65 // Heating degree days (ref-65°F)\n",
    "hdd65_era5_df = download_era5_data(\"hdd65\")\n",
    "\n",
    "# hi35 // Number of Days with Heat Index > 35°C\n",
    "hi35_era5_df = download_era5_data(\"hi35\")\n",
    "\n",
    "# hi37 // Number of Days with Heat Index > 37°C\n",
    "hi37_era5_df = download_era5_data(\"hi37\")\n",
    "\n",
    "# hurs // Relative Humidity\n",
    "hurs_era5_df = download_era5_data(\"hurs\")\n",
    "\n",
    "# prpercnt // Precipitation Percent Change\n",
    "prpercnt_era5_df = download_era5_data(\"prpercnt\")\n",
    "\n",
    "# rx1day // Average Largest 1-Day Precipitation\n",
    "rx1day_era5_df = download_era5_data(\"rx1day\")\n",
    "\n",
    "# rx5day // Average Largest 5-Day Cumulative Precipitation\n",
    "rx5day_era5_df = download_era5_data(\"rx5day\")\n",
    "\n",
    "# tnn // Minimum of Daily Min-Temperature\n",
    "tnn_era5_df = download_era5_data(\"tnn\")\n",
    "\n",
    "# txx // Maximum of Daily Max-Temperature\n",
    "txx_era5_df = download_era5_data(\"txx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download: ERA5 variables that should probably be adopted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr // Precipitation // Garret (pgm-level climate data ingestion): Has a variable called \"Total wet day precipitation\", which measures total annually summed precipitation on days with precipitation > 1mm. // The two variables are similar but not identical. The variable \"pr\" at hand from the ERA5 data measures the average precipitation over a given time and potentially also includes smaller variation of rain below 1mm. The variable \"pr\" could therefore be useful to include, despite not gaining a lot of new knowledge.\n",
    "pr_era5_df = download_era5_data(\"pr\")\n",
    "\n",
    "# hd30 // Number of Hot Days (Tmax > 30°C) // Garret (pgm-level climate data ingestion): - // Overlaping with previously loaded variables hd35, hd40, hd42. Would do no harm, but does likely not add much new information.\n",
    "hd30_era5_df = download_era5_data(\"hd30\")\n",
    "\n",
    "# hd50 // Number of Hot Days (Tmax > 50°C) // Garret (pgm-level climate data ingestion): - // Overlaping with previously loaded variables hd35, hd40, hd42. Would do no harm, but does likely not add much new information.\n",
    "hd50_era5_df = download_era5_data(\"hd50\")\n",
    "\n",
    "# hi39 // Number of Days with Heat Index > 39°C // Garret (pgm-level climate data ingestion): Garret chose to not include an identical variable that was available on the data platform he used. Therefore, this variable could potentially be useful to include.\n",
    "hi39_era5_df = download_era5_data(\"hi39\")\n",
    "\n",
    "# hi41 // Number of Days with Heat Index > 41°C // Garret (pgm-level climate data ingestion): Garret chose to not include an identical variable that was available on the data platform he used. Therefore, this variable could potentially be useful to include.\n",
    "hi41_era5_df = download_era5_data(\"hi41\")\n",
    "\n",
    "# r50mm // Number of Days with Precipitation >50mm // Garret (pgm-level climate data ingestion): Only has a variable called \"Very heavy precipitation days\" = days with more than 20mm. Slight overlap with this variable, but the variable \"r50mm\" could potentially be useful to include, despite not gaining a lot of new knowledge.\n",
    "r50mm_era5_df = download_era5_data(\"r50mm\")\n",
    "\n",
    "# r95ptot // Precipitation amount during wettest days // Garret (pgm-level climate data ingestion): Garret chose to not include an identical variable \"Very wet day precipitation\" that was available on the data platform he used. Therefore, this variable could potentially be useful to include.\n",
    "r95ptot_era5_df = download_era5_data(\"r95ptot\")\n",
    "\n",
    "# tr23 // Number of Tropical Nights (T-min > 23°C) // Garret (pgm-level climate data ingestion): Has a similar variable \"tr\" which the number of nights > 20°C // This variable is slightluy different and would add new information to the dataset, despite being similar to the variable \"tr\".\n",
    "tr23_era5_df = download_era5_data(\"tr23\")\n",
    "\n",
    "# tr26 // Number of Tropical Nights (T-min > 26°C) // See reasoning for tr23\n",
    "tr26_era5_df = download_era5_data(\"tr26\")\n",
    "\n",
    "# tr29 // Number of Tropical Nights (T-min > 29°C) // See reasoning for tr23\n",
    "tr29_era5_df = download_era5_data(\"tr29\")\n",
    "\n",
    "# tr32 // Number of Tropical Nights (T-min > 32°C) // See reasoning for tr23\n",
    "tr32_era5_df = download_era5_data(\"tr32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download: ERA5 variables that should probably NOT be adopted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fd // Number of Frost Days (Tmin < 0°C) // Garret (pgm-level climate data ingestion): Has an almost identical variable // G: count variable // Here: Average over time, i.e. data period. Smoothed-out, long-term perspective of Frost Days; Less interesting for forecasting, so should not be included.\n",
    "fd_era5_df = download_era5_data(\"fd\")\n",
    "\n",
    "# id // Number of Ice Days (Tmax < 0°C) // Garret (pgm-level climate data ingestion): Has an almost identical variable // G: count variable // Here: Average over time, i.e. data period. Smoothed-out, long-term perspective of Ice Days; Less interesting for forecasting, so should not be included\n",
    "id_era5_df = download_era5_data(\"id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling: Merge all variable-specific dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning all variable-specific dataframes into one dictionary of dataframes\n",
    "- Easier filtering for which variables to include in the ingestion.\n",
    "- Simplified code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of dataframes with the respective variable names as labels, to be able name the value columns according to the variable name in the merged data set.\n",
    "dataframes_dict = {\n",
    "    # CRU variables that should definitely be adopted.\n",
    "    \"climate_tas\": tas_cru_df,\n",
    "    \"climate_tasmax\": tasmax_cru_df,\n",
    "    \"climate_tasmin\": tasmin_cru_df,\n",
    "    # ERA5 variables that should definitely be adopted.\n",
    "    \"climate_cdd65\": cdd65_era5_df,\n",
    "    \"climate_hd35\": hd35_era5_df,\n",
    "    \"climate_hd40\": hd40_era5_df,\n",
    "    \"climate_hd42\": hd42_era5_df,\n",
    "    \"climate_hdd65\": hdd65_era5_df,\n",
    "    \"climate_hi35\": hi35_era5_df,\n",
    "    \"climate_hi37\": hi37_era5_df,\n",
    "    \"climate_hurs\": hurs_era5_df,\n",
    "    \"climate_prpercnt\": prpercnt_era5_df,\n",
    "    \"climate_rx1day\": rx1day_era5_df,\n",
    "    \"climate_rx5day\": rx5day_era5_df,\n",
    "    \"climate_tnn\": tnn_era5_df,\n",
    "    \"climate_txx\": txx_era5_df,\n",
    "    # ERA5 variables that should probably be adopted.\n",
    "    \"climate_pr\": pr_era5_df,\n",
    "    \"climate_hd30\": hd30_era5_df,\n",
    "    \"climate_hd50\": hd50_era5_df,\n",
    "    \"climate_hi39\": hi39_era5_df,\n",
    "    \"climate_hi41\": hi41_era5_df,\n",
    "    \"climate_r50mm\": r50mm_era5_df,\n",
    "    \"climate_r95ptot\": r95ptot_era5_df,\n",
    "    \"climate_tr23\": tr23_era5_df,\n",
    "    \"climate_tr26\": tr26_era5_df,\n",
    "    \"climate_tr29\": tr29_era5_df,\n",
    "    \"climate_tr32\": tr32_era5_df,\n",
    "    # ERA5 variables that should probably NOT be adopted.\n",
    "    \"climate_fd\": fd_era5_df,\n",
    "    \"climate_id\": id_era5_df,\n",
    "}\n",
    "\n",
    "# Delete the standalone variable-specific dataframes to avoid confusion\n",
    "for key in dataframes_dict.keys():\n",
    "    cru_var = key.replace(\"climate_\", \"\") + \"_cru_df\"\n",
    "    era5_var = key.replace(\"climate_\", \"\") + \"_era5_df\"\n",
    "    if cru_var in globals():\n",
    "        del globals()[cru_var]\n",
    "    if era5_var in globals():\n",
    "        del globals()[era5_var]\n",
    "\n",
    "# Delete unnecessary objects after the loop finishes\n",
    "del key\n",
    "del cru_var\n",
    "del era5_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bring all dataframes in the dictionary to the same time period: Start from January 1990\n",
    "- Convert the \"Date\" column to a datetime object\n",
    "- Filter the data to only include data from January 1990 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to filter the time period to only include data from January 1990 onwards\n",
    "def filter_timeseries_1990(df):\n",
    "    # Convert the \"Date\" column to a datetime object\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    # Filter the DataFrame to only include data from January 1990 onwards\n",
    "    return df[df[\"Date\"] >= \"1990-01-01\"]\n",
    "\n",
    "# Apply filtering to all DataFrames in the dictionary\n",
    "dataframes_dict = {key: filter_timeseries_1990(df) for key, df in dataframes_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all variables from the dictionary into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge dataframes from a dictionary into a single DataFrame\n",
    "def merge_datasets_from_dict(dataframes):\n",
    "    # Initialize an empty DataFrame to start merging\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through the dictionary\n",
    "    for var_name, df in dataframes.items():\n",
    "        # Check if the DataFrame has the expected structure\n",
    "        if set(df.columns) != {\"Country\", \"Date\", \"Value\"}:\n",
    "            raise ValueError(f\"DataFrame for '{var_name}' does not have the expected columns: {df.columns}\")\n",
    "        \n",
    "        # Rename the 'Value' column to the variable name\n",
    "        df = df.rename(columns={\"Value\": var_name})\n",
    "\n",
    "        # Merge with the existing DataFrame\n",
    "        if merged_df.empty:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, df, on=[\"Country\", \"Date\"], how=\"outer\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Execute function and merge all DataFrames\n",
    "merged_df = merge_datasets_from_dict(dataframes_dict)\n",
    "\n",
    "# Clean up workspace by deleting the non-relevant DataFrames\n",
    "climate_variables_df = merged_df\n",
    "del merged_df\n",
    "del dataframes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling: Turn merged data set into a suitable VIEWS format\n",
    "- Add Month ID\n",
    "- Add Country ID\n",
    "- Control for changes in country codes over time, like Sudan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrangling: Inserting month_id column\n",
    "- Create month_id column based on the existing DateTime column \"Date\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the data to VIEWS format using the Ingester3 extensions\n",
    "climate_variables_df = pd.DataFrame.cm.from_datetime(climate_variables_df, datetime_col='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrangling: Inserting c_id column\n",
    "- Problem\n",
    "    - The CCKP data only provides historical climate data within current geographical borders. If a country had territorial changes within our data period (1990-now), we only have accurate data for the territory in the most recent definition.\n",
    "    - Example: Climate data for country Sudan (SDN) is for historical climate within today's borders of Sudan, i.e. northern Sudan.\n",
    "    - Proof: https://climateknowledgeportal.worldbank.org/country/sudan\n",
    "    - This can be confusing, as the pre-2011 Sudan, i.e. \"whole\" Sudan, had the same iso3-code \"SDN\".\n",
    "- Code options within ingester3:\n",
    "    - pd.DataFrame.cm.from_iso(df=climate_variables_df_c_id_1, iso_col='Country', month_col= None ) \n",
    "        - => Assumes the ISO3-codes apply to the current geographical configurations\n",
    "    - pd.DataFrame.cm.from_iso(df=climate_variables_df_c_id_1, iso_col='Country', month_col='month_id') \n",
    "        - => Assumes the ISO3-codes apply to the geographical configurations at a given month.\n",
    "        - => Generally misleading. ISO3-code SDN before 2011 was used for all of Sudan. The climate data at hand however does not.\n",
    "        - => As a result, the month column should ideally not be specified so that the ingester3 code uses the most up-to-date interpretations of the ISO3-Codes.\n",
    "        - => Alternatively, this approach can be used, if afterwards all rows with older c_id-interpretations of the ISO3-Codes are filtered out.\n",
    "- Consequence: Potential approaches\n",
    "    - Approach A: Specify month_col as \"month_id\". Then filter all countries to only keep the rows with the most recent c_id, if there are more than one.\n",
    "        - Dataframe: climate_variables_df_A\n",
    "        - => Accurate data. \n",
    "        - => Output: Only country-months that exist in the VIEWS database. \n",
    "        - => Example: All pre-2011 data on historical climate in northern Sudan (c_id 245) is filtered out.\n",
    "        - => Con: Code is longer and potentially more prone to errors. \n",
    "    - Approach B: Specify month_col as \"None\".\n",
    "        - Dataframe: climate_variables_df_B\n",
    "        - => Also accurate data.\n",
    "        - => Less error prone, as it only uses ingester3 functions.\n",
    "        - => Output: Produces country-months that are not useful to VIEWS, but likely also not harmful.\n",
    "        - => Example: \"SDN\" is correctly coded as c_id \"245\" for the entire data period. \"245\" represents the current Sudan, i.e. northern Sudan. This is coherent with the CCKP climate data at hand, which for every time point of SDN represents historical climate data for northern Sudan. However, c_id 245 only exists in the VIEWS data base from July 2011 onwards. So, every row of the c_id 245 (northern Sudan) from January 1990 to June 2011 is obsolete.\n",
    "\n",
    "- **Open Question for Jim and Mihai**: Is it a problem, if we have obsolete data, like pre-2011 (northern) Sudan/SDN/245 data, even though the c_id 245 did not exist before 2011? Does ingester3 just filter them out?\n",
    "    - If yes: Go with Approach B.\n",
    "    - If no: Go with Approach A.\n",
    "- **Second Question/Idea to try in January**\n",
    "    - Maybe the obsolete data in Approach B can be filtered out, by soft-validating not on the basis of the ISO3-Code, but on the c_id variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrangling: Inserting c_id column // Approach A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach A: Step 1\n",
    "- Soft-validate and filter for country-months that exist in VIEWS, based on month_id and ISO3-code.\n",
    "- Create month-specific c_id, by specifying month_col='month_id'.\n",
    "- Note: After this step, this data is wrongly coded and NEEDS to be filtered in a second step.\n",
    "- Explanation (see also above)\n",
    "    - The output after step 1 of approach A is wrong, as the month-specific coding of the c_id means that ISO3-Codes that changed meaning within our data period (1990-now), are coded in the meaning of their specific month. This wrong data needs to be filtered out in a step 2.\n",
    "    - Example: ISO3-code SDN before 2011 was used for all of Sudan. However, the climate data at hand for \"SDN\" always refers to the modern northern Sudan borders. Therefore, the pre July 2011 coding of \"SDN\" as c_id \"59\" (whole Sudan) and not \"245\" (northern Sudan) is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft validation: Create valid_id and assign value \"true\" only to the country_months that resonate with the VIEWS database.\n",
    "climate_variables_df_A = pd.DataFrame.cm.soft_validate_iso(climate_variables_df, iso_col='Country', month_col='month_id')\n",
    "\n",
    "# Filter country-months for valid_id == True\n",
    "climate_variables_df_A = climate_variables_df_A[climate_variables_df_A.valid_id==True]\n",
    "\n",
    "# Create the c_id column\n",
    "climate_variables_df_A = pd.DataFrame.cm.from_iso(df=climate_variables_df_A, iso_col='Country', month_col='month_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach A: Step 2\n",
    "\n",
    "- Filter the dataset to keep only the rows with the latest/most up-to-date 'c_id' for each 'Country'.\n",
    "- If an ISO3-code represents different geographical areas at different points in time, we only keep the most recent.\n",
    "- This ensures that climate data from a country's geographical area today is not used as data for a country with a identical ISO3-code but a different geographical area.\n",
    "\n",
    "- Obvious example: Sudan (SDN)\n",
    "    - In the climate data at hand, the ISO3-Code \"SDN\" is used to label historical data for the region of today's (northern) Sudan.\n",
    "    - For July 2011 onwards, the month-specific ingester3 coding of c_id codes this correctly as c_id \"245\".\n",
    "    - However, for pre-July 2011, the month-specific ingester3 coding of c_id codes the country-months as having the c_id \"59\", which represents all of Sudan.\n",
    "    - The problem stems from Sudan changing shape in 2011, but keeping the same ISO3-Code \"SDN\".\n",
    "    - Therefore, the following lines of code filter and delete any rows with the ISO3-Code \"SDN\" that have the wrong c_id \"59\" assigned to them.\n",
    "    - We are left with only rows of northern Sudan (c_id 245) from July 2011 onwards, which marks the creation of the new state Sudan, that incidentally kept using the ISO3-Code \"SDN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by 'Country', 'c_id', and 'month_id' to ensure the latest month is at the end for each combination\n",
    "climate_variables_df_A = climate_variables_df_A.sort_values(by=['Country', 'c_id', 'month_id'], ascending=[True, True, True])\n",
    "\n",
    "# Identify the latest 'c_id' for each 'Country'\n",
    "latest_cid_per_country = climate_variables_df_A.groupby('Country').tail(1)['c_id']\n",
    "\n",
    "# Filter the dataset to keep only the rows with the latest 'c_id' for each 'Country'\n",
    "climate_variables_df_A = climate_variables_df_A[climate_variables_df_A['c_id'].isin(latest_cid_per_country)]\n",
    "\n",
    "# Drop unneccessary objects\n",
    "del latest_cid_per_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling: Inserting c_id column // Approach B\n",
    "- Soft-validate and filter for country-months that exist in VIEWS, based on month_id and ISO3-code.\n",
    "- Create c_id based on the most up-to-date meaning of the ISO3-Codes, by specifying month_col= None.\n",
    "\n",
    "- Problem: For countries with ISO3-Codes that had territorial changes in the data period, this creates obsolete data.\n",
    "    - Soft validation does not filter them out, because the ISO3-Code *does* exist. \n",
    "        - **Idea**: Maybe one can soft-validate not on the basis of the ISO3-Code, but on the newly created c_id variable?\n",
    "    - The obsolete data is not wrong, but just not useful to Views.\n",
    "\n",
    "- Example: Sudan\n",
    "    - Using this approach, the ISO3-Code \"SDN\" is correctly interpreted as representing northern Sudan for all data points. The c_id for modern, northern Sudan is 245.\n",
    "    - However, in the VIEWS data base, the c_id 245 only exists from July 2011 onwards.\n",
    "    - Therefore, all datapoints from January 1990 to June 2011 is not useful for VIEWS and could create problems during the ingestion.\n",
    "\n",
    "\n",
    "- Further cases to which this applies\n",
    "    - SRB/ Serbia: Independence of Kosovo in 2008. Territory changed, but Serbian ISO3-Code remained identical.\n",
    "    - ETH/ Ethiopia: Independence of Eritrea in 1993. Territory changed, but Ethiopian ISO3-Code remained identical.\n",
    "    - IDN/ Indonesia: Independence of East-Timor in 2002. Territory changed, but Indonesian ISO3-Code remained identical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft validation: Create valid_id and assign value \"true\" only to the country_months that resonate with the VIEWS database.\n",
    "climate_variables_df_B = pd.DataFrame.cm.soft_validate_iso(climate_variables_df, iso_col='Country', month_col='month_id')\n",
    "\n",
    "# Filter country-months for valid_id == True\n",
    "climate_variables_df_B = climate_variables_df_B[climate_variables_df_B.valid_id==True]\n",
    "\n",
    "# Create the c_id column\n",
    "climate_variables_df_B = pd.DataFrame.cm.from_iso(df=climate_variables_df_B, iso_col='Country', month_col=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Experimentation] Trying to soft-validate on c_id variable to filter out obsolete data in Approach B.\n",
    "- Does not seem to work. Potential arguments in \"iso_col\" seem to be limited to ISO-Codes.\n",
    "- Output: Every row is intepreted as invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_variables_df_B2 = pd.DataFrame.cm.soft_validate_iso(climate_variables_df_B, iso_col='c_id', month_col='month_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "# Proof:  Country-level data is always following current geoghraphical borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking precipitation, as there is probably a bigger difference between the two countries.\n",
    "\n",
    "# # Filter data for Sudan pre- and post-July 2011\n",
    "# sudan_pre_july_2011 = climate_variables_df_A[climate_variables_df_A['c_id'] == 59]\n",
    "# sudan_post_july_2011 = climate_variables_df_A[climate_variables_df_A['c_id'] == 245]\n",
    "# south_sudan_post_july_2011 = climate_variables_df_A[climate_variables_df_A['c_id'] == 246]\n",
    "\n",
    "# # Calculate summary statistics for the variable 'climate_pr'\n",
    "# summary_pre = sudan_pre_july_2011['climate_pr'].describe()\n",
    "# summary_post = sudan_post_july_2011['climate_pr'].describe()\n",
    "# summary_post_ssd = south_sudan_post_july_2011['climate_pr'].describe()\n",
    "\n",
    "# # Print the summaries\n",
    "# print(\"Summary statistics for 'climate_pr' before July 2011 (c_id = 59):\\n\", summary_pre)\n",
    "# print(\"\\nSummary statistics for 'climate_pr' after July 2011 (c_id = 245):\\n\", summary_post)\n",
    "\n",
    "# # Optional: Check if the summaries are identical\n",
    "# identical = summary_pre.equals(summary_post)\n",
    "# print(\"\\nAre the summary statistics for Sudan identical?\", identical)\n",
    "\n",
    "# # Print the summary statistics for South Sudan\n",
    "# print(\"\\nSummary statistics for 'climate_pr' for SOUTH SUDAN after July 2011 (c_id = 246):\\n\", summary_post_ssd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean up environment after tests\n",
    "# del sudan_pre_july_2011\n",
    "# del sudan_post_july_2011\n",
    "# del south_sudan_post_july_2011\n",
    "\n",
    "# del summary_pre\n",
    "# del summary_post\n",
    "# del summary_post_ssd\n",
    "\n",
    "# del identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: Precipitation in the different territorial variations of Sudan\n",
    "#### Ergo: We have country-level data only for current geographical borders\n",
    "- The precipitation for Sudan is very similar in both periods.\n",
    "- The precipitation is much higher in South Sudan in post-2011 compared to the post-2011 numbers from (North) Sudan.\n",
    "\n",
    "- This suggests, that the SDN data is always exlusively for Northern Sudan, and that the data for South Sudan is separate.\n",
    "\n",
    "- Therefore, previous geographic configurations for countries, which have independent c_id's in VIEWS, are not covered by this data.\n",
    "- This suggests: The data is always structured along the current geographic specifications of global gountries today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "# Brainstorm: Further problems with the data\n",
    "\n",
    "- Question: Which countries were dropped from the data during the soft validation and filtering process?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries dropped from the dataset:\n",
      "ABW: Aruba\n",
      "AIA: Anguilla\n",
      "ALA: Åland Islands\n",
      "ASM: American Samoa\n",
      "ATF: French Southern Territories\n",
      "BES: Bonaire, Sint Eustatius and Saba\n",
      "BLM: Saint Barthélemy\n",
      "BMU: Bermuda\n",
      "BVT: Bouvet Island\n",
      "CCK: Cocos (Keeling) Islands\n",
      "COK: Cook Islands\n",
      "CUW: Curaçao\n",
      "CXR: Christmas Island\n",
      "CYM: Cayman Islands\n",
      "FRO: Faroe Islands\n",
      "GGY: Guernsey\n",
      "GIB: Gibraltar\n",
      "GLP: Guadeloupe\n",
      "GRL: Greenland\n",
      "GUF: French Guiana\n",
      "GUM: Guam\n",
      "HKG: Hong Kong\n",
      "HMD: Heard Island and McDonald Islands\n",
      "IMN: Isle of Man\n",
      "IOT: British Indian Ocean Territory\n",
      "JEY: Jersey\n",
      "KSV: Invalid code: KSV\n",
      "MAC: Macao\n",
      "MAF: Saint Martin (French part)\n",
      "MNP: Northern Mariana Islands\n",
      "MSR: Montserrat\n",
      "MTQ: Martinique\n",
      "MYT: Mayotte\n",
      "NCL: New Caledonia\n",
      "NFK: Norfolk Island\n",
      "NIU: Niue\n",
      "PCN: Pitcairn\n",
      "PRI: Puerto Rico\n",
      "PSE: Palestine, State of\n",
      "PYF: French Polynesia\n",
      "REU: Réunion\n",
      "SHN: Saint Helena, Ascension and Tristan da Cunha\n",
      "SJM: Svalbard and Jan Mayen\n",
      "SPM: Saint Pierre and Miquelon\n",
      "SXM: Sint Maarten (Dutch part)\n",
      "TCA: Turks and Caicos Islands\n",
      "TKL: Tokelau\n",
      "UMI: United States Minor Outlying Islands\n",
      "VAT: Holy See (Vatican City State)\n",
      "VGB: Virgin Islands, British\n",
      "VIR: Virgin Islands, U.S.\n",
      "WLF: Wallis and Futuna\n"
     ]
    }
   ],
   "source": [
    "# distinct values in the variable \"Country\" in the dataframe climate_variables_df\n",
    "distinct_countries = climate_variables_df ['Country'].unique()\n",
    "\n",
    "# distinct values in the variable \"Country\" in the dataframe climate_variables_df_B\n",
    "distinct_countries_B = climate_variables_df_B['Country'].unique()\n",
    "\n",
    "# Create a list with all countries that are in distinct_countries but not in distinct_countries_B\n",
    "countries_lost = [country for country in distinct_countries if country not in distinct_countries_B]\n",
    "\n",
    "# -----------------\n",
    "\n",
    "# Function to get country name from ISO-3 code\n",
    "def get_country_name(iso3):\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_3=iso3).name\n",
    "    except AttributeError:\n",
    "        return f\"Invalid code: {iso3}\"\n",
    "\n",
    "# Convert the ISO-3 codes in countries_lost to country names\n",
    "country_names = [get_country_name(code) for code in countries_lost]\n",
    "\n",
    "# Print the results\n",
    "print(\"Countries dropped from the dataset:\")\n",
    "for iso3, name in zip(countries_lost, country_names):\n",
    "    print(f\"{iso3}: {name}\")\n",
    "\n",
    "# Delete obsolete objects\n",
    "del distinct_countries\n",
    "del distinct_countries_B\n",
    "del countries_lost\n",
    "del iso3\n",
    "del name\n",
    "del country_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: Categories of countries dropped\n",
    "\n",
    "- Autonomous regions and islands: \n",
    "    - They are coded as independent countries in the CCKP climate data\n",
    "    - Problem: By ommitting them, we lose all data on their climate and misrepresent the climate of the administering countries, as the data from the territories is not integrated into the administering countries data.\n",
    "    - At the same time, there is no elegant way to merge the data of the autonomous regions with their administering countries.\n",
    "    - Examples\n",
    "        - Åland is not coded as part of Finland. By ommitting it, we lose all data on Åland, as the Åland data is not integrated into Finland data. This also biases the data we have on Finland, as we lack the data on Åland.\n",
    "        - ABW, Aruba: Netherlands\n",
    "        - AIA, Anguilla: UK\n",
    "        - ASM, American Samoa: USA\n",
    "        - ATF, French Southern Territories: France\n",
    "        - BVT, Bouvet Island: Norway\n",
    "        - FRO, Faroe Islands: Denmark\n",
    "        - GRL, Greenland: Denmark\n",
    "        - MAC, Macao: China\n",
    "        - HKG, Hong Kong: China\n",
    "        - ...\n",
    "\n",
    "- Disputed and unrecognized territories\n",
    "    - KSV/XKX, Kosovo\n",
    "    - PSE, Palestine\n",
    "\n",
    "- Small states\n",
    "    - VAT, Vatican"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
